{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import notebookutil as nbu\n",
    "sys.meta_path.append(nbu.NotebookFinder())\n",
    "import datasets\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import roc_auc\n",
    "import estimator_kmeans as kmeans\n",
    "import estimator_knn as knn\n",
    "import estimator_nn as nn\n",
    "import estimator_rssibased as rssie\n",
    "from datetime import datetime\n",
    "import json\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path = data/raw/0[12]_[01][123]_0[1234]*_*\n",
      "data/raw/01_01_01_4F実験室_XperiaZ3_胸ポケット_裏上_正常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_01_02_4F実験室_XperiaZ3_カバン_裏上_正常_まっすぐ帰宅\n",
      "...x..........................\n",
      "data/raw/01_01_03_4F実験室_XperiaZ3_胸ポケット_裏上_正常_5秒後まっすぐ帰宅\n",
      ".........................x....\n",
      "data/raw/01_01_04_4F実験室_XperiaZ3_カバン_裏上_正常_5秒後まっすぐ帰宅\n",
      ".....................x........\n",
      "data/raw/01_02_01_4F実験室_XperiaZ3_胸ポケット_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/01_02_02_4F実験室_XperiaZ3_ズボン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/01_02_03_4F実験室_XperiaZ3_カバン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/01_03_01_4F実験室_XperiaZ3_胸ポケット_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_03_02_4F実験室_XperiaZ3_ズボン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_03_03_4F実験室_XperiaZ3_カバン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_11_01_エネマネハウス_XperiaZ3_胸ポケット_裏上_正常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_11_02_エネマネハウス_XperiaZ3_カバン_裏上_正常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_11_03_エネマネハウス_XperiaZ3_胸ポケット_裏上_正常_5秒後まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_11_04_エネマネハウス_XperiaZ3_カバン_裏上_正常_5秒後まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_12_01_エネマネハウス_XperiaZ3_胸ポケット_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/01_12_02_エネマネハウス_XperiaZ3_ズボン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/01_12_03_エネマネハウス_XperiaZ3_カバン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/01_13_01_エネマネハウス_XperiaZ3_胸ポケット_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_13_02_エネマネハウス_XperiaZ3_ズボン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/01_13_03_エネマネハウス_XperiaZ3_カバン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_01_01_4F実験室_iphone_胸ポケット_裏上_正常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_01_02_4F実験室_iphone_カバン_裏上_正常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_01_03_4F実験室_iphone_胸ポケット_裏上_正常_5秒後まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_01_04_4F実験室_iphone_カバン_裏上_正常_5秒後まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_02_01_4F実験室_iphone_胸ポケット_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/02_02_02_4F実験室_iphone_ズボン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/02_02_03_4F実験室_iphone_カバン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/02_03_01_4F実験室_iphone_胸ポケット_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_03_02_4F実験室_iphone_ズボン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_03_03_4F実験室_iphone_カバン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_11_01_エネマネハウス_iphone_胸ポケット_裏上_正常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_11_02_エネマネハウス_iphone_カバン_裏上_正常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_11_03_エネマネハウス_iphone_胸ポケット_裏上_正常_5秒後まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_11_04_エネマネハウス_iphone_カバン_裏上_正常_5秒後まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_12_01_エネマネハウス_iphone_胸ポケット_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/02_12_02_エネマネハウス_iphone_ズボン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/02_12_03_エネマネハウス_iphone_カバン_裏上_異常_まっすぐ外出\n",
      "..............................\n",
      "data/raw/02_13_01_エネマネハウス_iphone_胸ポケット_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_13_02_エネマネハウス_iphone_ズボン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n",
      "data/raw/02_13_03_エネマネハウス_iphone_カバン_裏上_異常_まっすぐ帰宅\n",
      "..............................\n"
     ]
    }
   ],
   "source": [
    "# data loader\n",
    "ds = datasets.load('data/raw/0[12]_[01][123]_0[1234]*_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# general estimator test\n",
    "def eval_estimator(\n",
    "    model,\n",
    "    sensor_type = ['rssi.a','rssi.b', ['linear_accel[0]','linear_accel[1]','linear_accel[2]']],\n",
    "    n_record = 3,\n",
    "    base = '01_11_01',\n",
    "    normal = '^01_11',\n",
    "    anomaly = '^01_1[23]',\n",
    "    ms_interval = 20,\n",
    "    ma_window = 3,\n",
    "    n_train = 3,\n",
    "    normalize = True):\n",
    "    \n",
    "    # recalc input\n",
    "    drop_interval = int(ms_interval / 20)\n",
    "    \n",
    "    # get data\n",
    "    dfl_t = datasets.get_data(ds, title=base, before=n_record,\n",
    "                              column=sensor_type, drop_interval=drop_interval)[:(n_train + 1)]\n",
    "    dfl_n = datasets.get_data(ds, title=normal, before=n_record,\n",
    "                              column=sensor_type, drop_interval=drop_interval)\n",
    "    dfl_o = datasets.get_data(ds, title=anomaly, before=n_record,\n",
    "                              column=sensor_type, drop_interval=drop_interval)\n",
    "    \n",
    "    # moving average\n",
    "    dfl_t = datasets.moving_average(dfl_t, window=ma_window, min_periods=ma_window)\n",
    "    dfl_n = datasets.moving_average(dfl_n, window=ma_window, min_periods=ma_window)\n",
    "    dfl_o = datasets.moving_average(dfl_o, window=ma_window, min_periods=ma_window)\n",
    "\n",
    "    # normalize\n",
    "    if normalize == True:\n",
    "        dfl_t_n = datasets.normalize_by_base_data(dfl_t, dfl_t, sensor_type)\n",
    "        dfl_n_n = datasets.normalize_by_base_data(dfl_t, dfl_n, sensor_type)\n",
    "        dfl_o_n = datasets.normalize_by_base_data(dfl_t, dfl_o, sensor_type)\n",
    "\n",
    "    # get numpy array\n",
    "    data_2d_t = [df.as_matrix() for df in dfl_t_n]\n",
    "    data_2d_n = [df.as_matrix() for df in dfl_n_n]\n",
    "    data_2d_o = [df.as_matrix() for df in dfl_o_n]\n",
    "\n",
    "    # to list of numpy.array\n",
    "    data_t = [d.ravel() for d in data_2d_t]\n",
    "    data_n = [d.ravel() for d in data_2d_n]\n",
    "    data_o = [d.ravel() for d in data_2d_o]\n",
    "    \n",
    "    # get auc score\n",
    "    model.fit(data_t)\n",
    "    score_n = model.decision_function(data_n)\n",
    "    score_o = model.decision_function(data_o)\n",
    "    auc = roc_auc.get_auc_from_normal_outlier(score_n, score_o, graph=False)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "#eval_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test case: 7035\n",
      "imcomplete test case: 7035\n",
      "1 / 7035\n",
      "11 / 7035\n",
      "21 / 7035\n",
      "31 / 7035\n",
      "41 / 7035\n",
      "51 / 7035\n",
      "61 / 7035\n",
      "71 / 7035\n",
      "81 / 7035\n",
      "91 / 7035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-c48044706ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-c48044706ac0>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_grid_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remove_unavailable_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-c48044706ac0>\u001b[0m in \u001b[0;36m_run_test\u001b[0;34m(df, models)\u001b[0m\n\u001b[1;32m    103\u001b[0m         auc = eval_estimator(models[t['model_idx']], base=base, normal=normal, anomaly=anomaly,\n\u001b[1;32m    104\u001b[0m                              \u001b[0mn_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensor_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_record\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_record'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                              ms_interval=t['ms_interval'], ma_window=t['ma_window'])\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-f0fa5746ceb5>\u001b[0m in \u001b[0;36meval_estimator\u001b[0;34m(model, sensor_type, n_record, base, normal, anomaly, ms_interval, ma_window, n_train, normalize)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdfl_t_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_by_base_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfl_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfl_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdfl_n_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_by_base_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfl_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfl_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdfl_o_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_by_base_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfl_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfl_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/work/jupyter.git/009.dkj_learn/datasets.ipynb\u001b[0m in \u001b[0;36mnormalize_by_base_data\u001b[0;34m(dfl_base, dfl_target, column)\u001b[0m\n",
      "\u001b[0;32m/data/work/jupyter.git/009.dkj_learn/datasets.ipynb\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(dfl, mean_std, column)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right, name, na_op)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         )\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_construct_result\u001b[0;34m(left, result, index, name, dtype)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2756\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# grid search implementation (under test)\n",
    "def _get_estimator_models():\n",
    "    models = []\n",
    "    \n",
    "    # k-means based estimator\n",
    "    range_n_clusters = np.arange(1, 10, 2)\n",
    "    mesh_data = np.meshgrid(range_n_clusters)\n",
    "    for n_clusters, in zip(mesh_data[0].ravel()):\n",
    "        models.append(kmeans.EstimatorKmeans(n_clusters=n_clusters))\n",
    "    \n",
    "    # knn based estimator\n",
    "    range_n_neighbors = np.arange(1, 10, 2)\n",
    "    mesh_data = np.meshgrid(range_n_neighbors)\n",
    "    for n_neighbors, in zip(mesh_data[0].ravel()):\n",
    "        models.append(knn.EstimatorKNN(n_neighbors=n_neighbors))\n",
    "    \n",
    "    # nn based estimator\n",
    "    range_n_training_epochs = np.array([100])\n",
    "    range_n_hidden_nodes = np.array([4, 8, 16, 32])\n",
    "    mesh_data = np.meshgrid(range_n_training_epochs, range_n_hidden_nodes)\n",
    "    for n_training_epochs, n_hidden_nodes in zip(mesh_data[0].ravel(), mesh_data[1].ravel()):\n",
    "        models.append(nn.EstimatorNN(num_of_hidden_nodes=n_hidden_nodes,\n",
    "                                     num_of_training_epochs=n_training_epochs))\n",
    "    \n",
    "    # rssi based estimator\n",
    "    models.append(rssie.EstimatorRssiBased())\n",
    "    \n",
    "    return models\n",
    "\n",
    "def _get_grid_test_case(models):\n",
    "    # parameters other than algorithm specific\n",
    "    sensor_master = [\n",
    "        ['rssi.a', 'rssi.b'],\n",
    "        ['rssi.a', 'rssi.b', ['acceleration.x', 'acceleration.y', 'acceleration.z']],\n",
    "        ['rssi.a', 'rssi.b', ['gyro.rotationRate.x', 'gyro.rotationRate.y', 'gyro.rotationRate.z']],\n",
    "        ['rssi.a', 'rssi.b', ['magneticField.x', 'magneticField.y', 'magneticField.z']],\n",
    "        ['rssi.a', 'rssi.b', ['attitude.roll', 'attitude.pitch', 'attitude.yaw']],\n",
    "        ['rssi.a', 'rssi.b', ['rotationRate.x', 'rotationRate.y', 'rotationRate.z']],\n",
    "        ['rssi.a', 'rssi.b', ['gravity.x', 'gravity.y', 'gravity.z']],\n",
    "        ['rssi.a', 'rssi.b', ['userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z']],\n",
    "    ]\n",
    "    sensor_master_s = [json.dumps(s) for s in sensor_master] # to be combinationable\n",
    "\n",
    "    range_n_record = np.array([1, 5, 20])\n",
    "    range_n_train = np.array([1, 5, 10, 20, 100])\n",
    "    range_ms_interval = np.array([20, 60, 100])\n",
    "    range_ma_window = np.arange(1, 4, 2)\n",
    "    \n",
    "    mesh_data = np.meshgrid(range(len(models)), range_n_record, range_n_train,\n",
    "                            range_ms_interval, range_ma_window, range(len(sensor_master_s)))\n",
    "\n",
    "    # create grid test case\n",
    "    test_case = []\n",
    "    for model_idx, n_record, n_train, ms_interval, ma_window, sensor_idx in zip(mesh_data[0].ravel(), mesh_data[1].ravel(), mesh_data[2].ravel(),\n",
    "               mesh_data[3].ravel(), mesh_data[4].ravel(), mesh_data[5].ravel()):\n",
    "        model = models[model_idx]\n",
    "                            \n",
    "        # save test case and result\n",
    "        _t = {'model_idx': model_idx, 'n_record': n_record, 'n_train': n_train,\n",
    "              'ms_interval': ms_interval, 'ma_window': ma_window, 'sensor_type': sensor_master_s[sensor_idx]}\n",
    "        _t.update(model.get_params())\n",
    "        _t['type'] = model.get_type()\n",
    "        test_case.append(_t)\n",
    "    \n",
    "    # create df for test case\n",
    "    df = pd.DataFrame(test_case)\n",
    "    return df\n",
    "\n",
    "def _remove_unavailable_test_case(df):\n",
    "    # remove unavailable test case\n",
    "    df = df[~(df['n_train'] < df['n_neighbors'])]\n",
    "    df = df[~(df['n_train'] < df['n_clusters'])]\n",
    "    df = df[~((df['type'] == 'rssi_based') & (df['sensor_type'].apply(lambda x: len(json.loads(x)) > 2)))]\n",
    "    df = df[~(df['n_record'] - df['ma_window'] < 0)]\n",
    "    return df\n",
    "\n",
    "def _run_test(df, models):\n",
    "    # set the data title\n",
    "    base = '02_11_01'\n",
    "    normal = '^02_11'\n",
    "    anomaly = '^02_1[23]'\n",
    "    \n",
    "    csv_fname = 'test_record_%s__%s__%s.csv' % (base, normal, anomaly) \n",
    "\n",
    "    # if auc is already computed in some test case, merge the result. \n",
    "    if os.path.exists(csv_fname):\n",
    "        df_past = read_csv(csv_fname)\n",
    "        keys = list(df.columns.values)\n",
    "        df = pd.merge(df, df_past, on=keys, how='outer')\n",
    "    else:\n",
    "        df['auc'] = np.nan\n",
    "    \n",
    "    imcomplete_test_case = len([x for x in df['auc'].values if np.isnan(x)])\n",
    "    print('total test case: %d' % (len(df.index)))\n",
    "    print('imcomplete test case: %d' %(imcomplete_test_case))\n",
    "    \n",
    "    # run test\n",
    "    for i, (k, t) in enumerate(df[df['auc'].isnull()].iterrows()):\n",
    "        if i % 10 == 0:\n",
    "            print(\"%d / %d at %s\"%(i+1, imcomplete_test_case, datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")))\n",
    "            df.to_csv(csv_fname )\n",
    "\n",
    "        auc = eval_estimator(models[t['model_idx']], base=base, normal=normal, anomaly=anomaly,\n",
    "                             n_train=t['n_train'], sensor_type=json.loads(t['sensor_type']), n_record=t['n_record'],\n",
    "                             ms_interval=t['ms_interval'], ma_window=t['ma_window'])\n",
    "        df.loc[[k], 'auc'] = auc\n",
    "    \n",
    "    df.to_csv(csv_fname )\n",
    "    return df\n",
    "\n",
    "def test():\n",
    "    models = _get_estimator_models()\n",
    "    df = _get_grid_test_case(models)\n",
    "    df = _remove_unavailable_test_case(df)\n",
    "    df = _run_test(df, models)\n",
    "    \n",
    "    return df\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_csv(fname):\n",
    "    df = pd.read_csv(fname, index_col=0)\n",
    "    return df\n",
    "#read_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
