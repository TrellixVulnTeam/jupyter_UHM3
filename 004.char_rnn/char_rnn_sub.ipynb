{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict the next char\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_mini_batch(train_data, size_of_mini_batch, length_of_sequences):\n",
    "    inputs  = ''\n",
    "    outputs = ''\n",
    "    for _ in range(size_of_mini_batch):\n",
    "        index   = random.randint(0, len(train_data) - length_of_sequences - 1)\n",
    "        inputs  += train_data[index:index + length_of_sequences]\n",
    "        outputs += train_data[index + length_of_sequences]\n",
    "    inputs = np.eye(num_of_char)[[ord(x) for x in inputs if ord(x) < 128]]\n",
    "    outputs = np.eye(num_of_char)[[ord(x) for x in outputs if ord(x) < 128]]\n",
    "    inputs  = inputs.reshape(-1, length_of_sequences, 128)\n",
    "    outputs = outputs.reshape(-1, 128)\n",
    "    return (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_prediction_initial(train_data, index, length_of_sequences):\n",
    "    inputs = train_data[index:index + length_of_sequences]\n",
    "    return np.eye(num_of_char)[[ord(x) for x in inputs if ord(x) < 128]]    \n",
    "#inputs, _  = make_prediction_initial(train_data, 0, length_of_initial_sequences)\n",
    "#inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_path             = \"./input/stieve_jobs_small.txt\"\n",
    "num_of_char                 = 128\n",
    "num_of_input_nodes          = 128\n",
    "num_of_hidden_nodes         = 512\n",
    "num_of_output_nodes         = 128\n",
    "length_of_sequences         = 50\n",
    "num_of_training_epochs      = 2010\n",
    "length_of_initial_sequences = 50\n",
    "num_of_prediction_epochs    = 1000\n",
    "size_of_mini_batch          = 20\n",
    "learning_rate               = 0.002\n",
    "forget_bias                 = 1.0\n",
    "train_dir                   = 'train_small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data = np.load(train_data_path)\n",
    "f = open(train_data_path)\n",
    "text = f.read()\n",
    "f.close()\n",
    "train_data = ''.join([x for x in text if ord(x) < 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(input_ph, size_of_mini_batch_ph, lstm_output_keep_prob):\n",
    "    with tf.name_scope(\"inference\") as scope:\n",
    "        weight1_var = tf.Variable(tf.truncated_normal([num_of_input_nodes, num_of_hidden_nodes], stddev=0.1), name=\"weight1\")\n",
    "        weight2_var = tf.Variable(tf.truncated_normal([num_of_hidden_nodes, num_of_output_nodes], stddev=0.1), name=\"weight2\")\n",
    "        bias1_var   = tf.Variable(tf.truncated_normal([num_of_hidden_nodes], stddev=0.1), name=\"bias1\")\n",
    "        bias2_var   = tf.Variable(tf.truncated_normal([num_of_output_nodes], stddev=0.1), name=\"bias2\")\n",
    "\n",
    "        weight1_hist = tf.histogram_summary(\"layer1/weights\", weight1_var)\n",
    "        weight2_hist = tf.histogram_summary(\"layer2/weights\", weight2_var)\n",
    "        bias1_hist = tf.histogram_summary(\"layer1/biases\", bias1_var)\n",
    "        bias2_hist = tf.histogram_summary(\"layer2/biases\", bias2_var)\n",
    "        \n",
    "        # pre rnn\n",
    "        in1 = tf.transpose(input_ph, [1, 0, 2])         # (batch, sequence, data) -> (sequence, batch, data)\n",
    "        in2 = tf.reshape(in1, [-1, num_of_input_nodes]) # (sequence, batch, data) -> (sequence * batch, data)\n",
    "        in3 = tf.matmul(in2, weight1_var) + bias1_var\n",
    "        in4 = tf.split(0, length_of_sequences, in3)     # sequence * (batch, data)\n",
    "\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(num_of_hidden_nodes, forget_bias=forget_bias, state_is_tuple=True)\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=lstm_output_keep_prob)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2, state_is_tuple=True)\n",
    "        initial_state = cell.zero_state(size_of_mini_batch_ph, tf.float32)\n",
    "        rnn_output, states_op = tf.nn.rnn(cell, in4, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "        output_op = tf.matmul(rnn_output[-1], weight2_var) + bias2_var\n",
    "    return output_op, rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(output_op):\n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_op, supervisor_ph))\n",
    "        loss_op = cross_entropy\n",
    "        tf.scalar_summary(\"loss\", loss_op)\n",
    "    return loss_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(loss_op):\n",
    "    with tf.name_scope(\"training\") as scope:\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        #optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss_op)\n",
    "    return training_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from train_small/translate.ckpt-1900\n",
      "train#1900, train loss: 3.059807e-01\n",
      "checkpoint saved train_small/translate.ckpt-1900\n",
      "train#1910, train loss: 2.885838e-01\n",
      "train#1920, train loss: 5.755346e-01\n",
      "train#1930, train loss: 3.817467e-01\n",
      "train#1940, train loss: 2.673748e-01\n",
      "train#1950, train loss: 6.097723e-01\n",
      "train#1960, train loss: 5.724652e-01\n",
      "train#1970, train loss: 4.388514e-01\n",
      "train#1980, train loss: 1.053753e+00\n",
      "train#1990, train loss: 6.318206e-01\n",
      "train#2000, train loss: 5.145615e-01\n",
      "checkpoint saved train_small/translate.ckpt-2000\n",
      "prediction: \n",
      "('outputs:', ', and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food w')\n",
      "prediction: \n",
      "('outputs:', 'o trust in somehow connect them looking forward; you can only connect the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the di')\n",
      "prediction: \n",
      "('outputs:', 'looking forward; you can only connect the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the differ')\n",
      "prediction: \n",
      "('outputs:', 'food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and I food with, and')\n",
      "prediction: \n",
      "('outputs:', 'class to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be priceless across to be')\n",
      "prediction: \n",
      "('outputs:', 'arying the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the differenc')\n",
      "prediction: \n",
      "('outputs:', 'the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a ')\n",
      "prediction: \n",
      "('outputs:', 'lligraphed. I had dropped out and intuition turned Coke bottles for the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the diff')\n",
      "prediction: \n",
      "('outputs:', \"he floor in somehow connect them looking friends' rooms, I decided to take the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at the difference in a week at t\")\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    input_ph      = tf.placeholder(tf.float32, [None, length_of_sequences, num_of_input_nodes], name=\"input\")\n",
    "    supervisor_ph = tf.placeholder(tf.float32, [None, num_of_output_nodes], name=\"supervisor\")\n",
    "    size_of_mini_batch_ph = tf.placeholder(tf.int32, name=\"size_of_mini_batch\")\n",
    "    lstm_output_keep_prob_ph = tf.placeholder(tf.float32, name=\"lstm_output_keep_prob\")\n",
    "\n",
    "    output_op, rnn_output = inference(input_ph, size_of_mini_batch_ph, lstm_output_keep_prob_ph)\n",
    "    loss_op = loss(output_op)\n",
    "    training_op = train(loss_op)\n",
    "\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.train.SummaryWriter(\"data\", graph=sess.graph)\n",
    "        \"\"\"\n",
    "        # random seed fix\n",
    "        random.seed(0)\n",
    "        np.random.seed(0)\n",
    "        tf.set_random_seed(0)\n",
    "        \"\"\"\n",
    "        epoch_start = 0\n",
    "        ckpt = tf.train.get_checkpoint_state(train_dir)\n",
    "        saver = tf.train.Saver()\n",
    "        if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n",
    "            print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            epoch_start = int(re.search(r\"(\\d+)$\", ckpt.model_checkpoint_path).group())\n",
    "        else:\n",
    "            print(\"Created model with fresh parameters.\")\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        for epoch in range(epoch_start, num_of_training_epochs):\n",
    "            inputs, supervisors = make_mini_batch(train_data, size_of_mini_batch, length_of_sequences)\n",
    "\n",
    "            train_dict = {\n",
    "                input_ph:      inputs,\n",
    "                supervisor_ph: supervisors,\n",
    "                size_of_mini_batch_ph: size_of_mini_batch,\n",
    "                lstm_output_keep_prob_ph: 0.5,\n",
    "            }\n",
    "            rnnout, _ = sess.run([rnn_output, training_op], feed_dict=train_dict)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                summary_str, train_loss = sess.run([summary_op, loss_op], feed_dict=train_dict)\n",
    "                summary_writer.add_summary(summary_str, epoch)\n",
    "                print(\"train#%d, train loss: %e\" % (epoch, train_loss))\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                f = saver.save(sess, train_dir + \"translate.ckpt\", global_step=epoch)\n",
    "                print(\"checkpoint saved %s\" % f)\n",
    "\n",
    "#        inputs = make_prediction_initial(train_data, len(train_data)-length_of_sequences, length_of_initial_sequences)\n",
    "        \n",
    "        for t in range(100, 1000, 100):\n",
    "            inputs = make_prediction_initial(train_data, len(train_data) - t, length_of_initial_sequences)\n",
    "            outputs = np.array([[0 for _ in range(128)]])\n",
    "\n",
    "            print(\"prediction: \")\n",
    "            for epoch in range(num_of_prediction_epochs):\n",
    "                pred_dict = {\n",
    "                    input_ph:  [inputs],\n",
    "                    size_of_mini_batch_ph: 1,\n",
    "                    lstm_output_keep_prob_ph: 1.0\n",
    "                }\n",
    "                output = sess.run(output_op, feed_dict=pred_dict)\n",
    "                output_onehotvec = np.eye(num_of_char)[[np.argmax(output)]]\n",
    "                inputs  = np.delete(inputs, 0, 0)\n",
    "                inputs  = np.append(inputs, output_onehotvec, 0)\n",
    "                outputs = np.append(outputs, output_onehotvec, 0)\n",
    "\n",
    "            outputs  = np.delete(outputs, 0, 0)\n",
    "            output_ascii = np.argmax(outputs.reshape(num_of_prediction_epochs, num_of_output_nodes), axis=1)\n",
    "            print(\"outputs:\", ''.join([chr(x) for x in output_ascii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
